{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting Rows with Specific Transliterations from the TLA Corpus\n",
        "\n",
        "This notebook loads a subset of the Thesaurus Linguae Aegyptiae (TLA) corpus, normalizes transliterations of Egyptian text, and extracts rows that contain **both** `3h3=k` and `nkht=k`.\n",
        "\n",
        "It is designed for research in historical linguistics or digital philology of Earlier Egyptian texts.\n",
        "\n",
        "---\n",
        "\n",
        "## Overview\n",
        "\n",
        "1. Load the corpus from HuggingFace Datasets  \n",
        "2. Normalize transliterations using a custom mapping  \n",
        "3. Search for rows containing both specific normalized terms  \n",
        "4. Display the filtered results\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "x88ySm3sL1ax"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BRzHRTrkRyqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Y6t9TRLjfYd"
      },
      "outputs": [],
      "source": [
        "!pip install datasets pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load TLA dataset from HuggingFace\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "dataset = load_dataset(\"thesaurus-linguae-aegyptiae/tla-Earlier_Egyptian_original-v18-premium\", split=\"train\")\n",
        "df = dataset.to_pandas()\n"
      ],
      "metadata": {
        "id": "_DTeyed3L5WD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Define normalization rules (based on Egyptological conventions)\n",
        "def normalize(text):\n",
        "    return (\n",
        "        text.replace(\"ꞽ\", \"E\")\n",
        "            .replace(\"ꜣ\", \"A\")\n",
        "            .replace(\"ꜥ\", \"3\")\n",
        "            .replace(\"ḫ\", \"kh\")\n",
        "            .replace(\"ṯ\", \"tj\")\n",
        "            .replace(\"š\", \"sh\")\n",
        "            .replace(\"ẖ\", \"x\")\n",
        "            .replace(\"ḥ\", \"h\")\n",
        "    )\n",
        "\n",
        "# Apply normalization\n",
        "df[\"transliteration_norm\"] = df[\"transliteration\"].fillna(\"\").apply(normalize)\n"
      ],
      "metadata": {
        "id": "ksauHNvAL8NY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Filter rows containing both '3h3=k' and 'nkht=k'\n",
        "mask = df[\"transliteration_norm\"].str.contains(\"3h3=k\") & df[\"transliteration_norm\"].str.contains(\"nkht=k\")\n",
        "df_filtered = df[mask]\n"
      ],
      "metadata": {
        "id": "H0iDuqD6L_Sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Display results\n",
        "df_filtered[[\"transliteration\", \"transliteration_norm\"]].head()"
      ],
      "metadata": {
        "id": "4H1B-siqMBk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample Output\n",
        "\n",
        "This table shows entries that contain both `3h3=k` and `nkht=k` in their normalized transliteration.\n",
        "\n",
        "| transliteration        | transliteration_norm |\n",
        "|------------------------|----------------------|\n",
        "| ...                    | ...                  |\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "xOwxqwb6MEll"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notes\n",
        "\n",
        "- This notebook assumes a basic understanding of Middle Egyptian transliteration.\n",
        "- The normalization scheme is simplified and may not cover all phonetic symbols.\n",
        "- Make sure `datasets` and `pandas` are installed in your environment.\n",
        "\n",
        "## Author\n",
        "Mio Ohashi  \n",
        "April 2025\n",
        "\n"
      ],
      "metadata": {
        "id": "0vuk26cYMIBH"
      }
    }
  ]
}